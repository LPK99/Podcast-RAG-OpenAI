{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Splitters\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Embedding Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Summarizer we'll use for Map Reduce\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 6 documents and the first one has 2103 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key='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')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\".\"], chunk_size=10000, chunk_overlap=3000)\n",
    "\n",
    "with open('transcript_text.txt','r') as f:\n",
    "    transcript = f.read()\n",
    "    docs = text_splitter.create_documents([transcript])\n",
    "\n",
    "num_docs = len(docs)\n",
    "\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "print (f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectors = embeddings.embed_documents([x.page_content for x in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trung\\anaconda3\\envs\\local_gpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'embeddings' is a list or array of 1536-dimensional embeddings\n",
    "\n",
    "# Choose the number of clusters, this can be adjusted based on the book's content.\n",
    "# I played around and found ~10 was the best.\n",
    "# Usually if you have 10 passages from a book you can tell what it's about\n",
    "num_clusters = 5\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 4, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the closest embeddings to the centroids\n",
    "\n",
    "# Create an empty list that will hold your closest points\n",
    "closest_indices = []\n",
    "\n",
    "# Loop through the number of clusters you have\n",
    "for i in range(num_clusters):\n",
    "    \n",
    "    # Get the list of distances from that particular cluster center\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "    \n",
    "    # Find the list position of the closest one (using argmin to find the smallest distance)\n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    # Append that position to your closest indices list\n",
    "    closest_indices.append(closest_index)\n",
    "    \n",
    "selected_indices = sorted(closest_indices)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain import LLMChain\n",
    "\n",
    "class MainContent(BaseModel):\n",
    "    main_content : str = Field(description='Summarize the main concept of the document in a short phrase (3 to 5 words) , like a book chapter')\n",
    "    sentence : str = Field(description=\"The sentence in the document that started discussing this concept\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=MainContent)\n",
    "\n",
    "map_prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Summarize the map concept of this text using a question the text is delimited by ``` \n",
    "    {format_instructions}\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    ''',\n",
    "    input_variables=['text'],\n",
    "    partial_variables={'format_instructions' : output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "selected_docs = [docs[doc] for doc in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain, document_variable_name=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to hold your summaries\n",
    "summary_list = []\n",
    "\n",
    "# Loop through a range of the lenght of your selected docs\n",
    "for i, doc in enumerate(selected_docs):\n",
    "    \n",
    "    # Go get a summary of the chunk\n",
    "    chunk_summary = combine_documents_chain.run([doc])\n",
    "    output = output_parser.parse(chunk_summary)\n",
    "    # Append that summary to your list\n",
    "    summary_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MainContent(main_content=\"OpenAI's goal and evolution\", sentence='The goal of open AI from the very beginning has been to make sure that artificial general intelligence by which remain autonomous systems, AI that can actually do most of the jobs and activities and tasks that people do, benefits all of humanity.'),\n",
       " MainContent(main_content=\"OpenAI's goal of benefiting humanity through artificial general intelligence\", sentence='The goal of open AI from the very beginning has been to make sure that artificial general intelligence by which remain autonomous systems, AI that can actually do most of the jobs and activities and tasks that people do, benefits all of humanity.'),\n",
       " MainContent(main_content='Role of open source models in the ecosystem', sentence=\"Well, open source is complicated. I'll describe to you my mental picture. I think that in the near term, open source is just helping companies produce useful.\"),\n",
       " MainContent(main_content='The concept of super alignment and the importance of building pro-social AI', sentence='What is super alignment and why invest in it now?'),\n",
       " MainContent(main_content='The possibility of AI becoming pro-social', sentence='The friendship piece, I think, is optional, but I do think that we want to have very pro-social AI.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_gpt",
   "language": "python",
   "name": "local_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
