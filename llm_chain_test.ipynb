{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'your-openai-api-key'\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS \n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the text into smaller chunks for indexing\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200, #striding over the text\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "with open('transcript.txt','r') as f:\n",
    "    transcript = f.read()\n",
    "    texts = text_splitter.split_text(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new Pydantic model with field descriptions and tailored for Twitter.\n",
    "class TranscriptionChapter(BaseModel):\n",
    "    summarization: str = Field(description=\"A short summarization of the transcript\")\n",
    "    number_of_chapters: int = Field(description=\"Number of chapters of main contents in this transcript\")\n",
    "    chapter: List[str] = Field(description=f\"List of {number_of_chapters} short chapter name of main contents and the sentence that each chapter start with in the transcript, using this format 'Chapter name:Sentence\")\n",
    "    sentences: List[str] = Field(description=f\"List of {number_of_chapters} main contents in the transcript and the first sentence each {chapter} begin with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output parser\n",
    "output_parser = PydanticOutputParser(pydantic_object=TranscriptionChapter)\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "                        template='''\n",
    "                        As a content curator, summarize the content in the following transcript with in chapter with sentences that each chapter begin in using this {format_instructions}\n",
    "                        {transcript}\n",
    "                        ''',\n",
    "                        input_variables=['transcript'],\n",
    "                        partial_variables={\"format_instructions\": output_parser.get_format_instructions()})\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "# Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=docsearch.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(query='Summarize the main contents concise and detailed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"424\\n00:00:1629\\nareas of higher thought, areas for empathy or other sort of aspects of everything from personality\\n425\\n00:00:1634\\nto processing.\\n426\\n00:00:1636\\nDo you think that the transformer architectures are the main thing that will just keep going\\n427\\n00:00:1640\\nand get us there?\\n428\\n00:00:1641\\nDo you think we'll need other architectures over time?\\n429\\n00:00:1643\\nSo I have to, I understand precisely what you're saying and I have to answer to this question.\\n430\\n00:00:1650\\nThe first is that in my opinion, the best way to think about the question of architecture\\n431\\n00:00:1655\\nis not in terms of a binary, is it enough?\\n432\\n00:00:1659\\nBut how much effort, what will be the cost of using this particular architecture?\\n433\\n00:00:1667\\nLike at this point, I don't think anyone doubts that the transformer architecture can do\\n434\\n00:00:1672\\namazing things, but maybe something else, maybe some modification could have some computer\\n435\\n00:00:1678\\nefficiency benefits.\\n436\\n00:00:1680\"), Document(page_content=\"00:00:1182\\nOr like let's suppose I upload some documents, some financial documents.\\n308\\n00:00:1186\\nSuppose they say something I want you to do some analysis and to make some conclusion\\n309\\n00:00:1189\\nand I want to take action on this basis and this conclusion.\\n310\\n00:00:1193\\nAnd it's like it's not a super hard task.\\n311\\n00:00:1195\\nAnd the model, these models clearly succeed on this task most of the time.\\n312\\n00:00:1199\\nBut because they don't succeed all the time and if it's a consequential decision I\\n313\\n00:00:1202\\nactually can't trust the model any of those times.\\n314\\n00:00:1204\\nAnd I have to verify the answer somehow.\\n315\\n00:00:1207\\nSo that's how I define reliability.\\n316\\n00:00:1208\\nIt's very similar to the self-driving situation, right?\\n317\\n00:00:1210\\nIf you have a self-driving car and it's like, does things mostly well?\\n318\\n00:00:1216\\nIt's not good enough.\\n319\\n00:00:1217\\nSituation is not as extreme as with a self-driving car, but that's what I mean by reliability.\\n320\\n00:00:1221\"), Document(page_content=\"352\\n00:00:1341\\nwill justify the cost of a large model.\\n353\\n00:00:1343\\nWhat do you think the role of open sources in the ecosystem?\\n354\\n00:00:1347\\nWell, open source is complicated.\\n355\\n00:00:1349\\nI'll describe to you my mental picture.\\n356\\n00:00:1352\\nI think that in the near term, open source is just helping companies produce useful.\\n357\\n00:00:1359\\nLike, let's see.\\n358\\n00:00:1360\\nWhy would one want to have an open source, but using open source model instead of a\\n359\\n00:00:1365\\nclosed source model that's hosted by some other company?\\n360\\n00:00:1368\\nI mean, I think it's very valid to want to be the final decider on the exact way in\\n361\\n00:00:1377\\nwhich you want your model to be used.\\n362\\n00:00:1379\\nFor you to make the decision of exactly how you want the model to be used and which use\\n363\\n00:00:1384\\ncase you wish to support.\\n364\\n00:00:1386\\nAnd I think there's going to be a lot of demand for open source models.\\n365\\n00:00:1388\"), Document(page_content=\"540\\n00:00:2048\\nbut it also have mean have deeper insight into the same subjects that we people are studying\\n541\\n00:00:2055\\nand looking into.\\n542\\n00:00:2056\\nIt means learn even faster than people.\\n543\\n00:00:2061\\nLike, what could such a eyes do?\\n544\\n00:00:2063\\nI don't know.\\n545\\n00:00:2064\\nCertainly, if such an AI were the basis of some artificial life, it would be,\\n546\\n00:00:2069\\nwell, how do you even think about it?\\n547\\n00:00:2071\\nIf you have some very powerful data center that's also alive in a sense,\\n548\\n00:00:2076\\nthat's what we're talking about.\\n549\\n00:00:2078\\nAnd when I imagine this world, my reaction is, gosh,\\n550\\n00:00:2081\\nthis is very unpredictable.\\n551\\n00:00:2082\\nWhat's going to happen?\\n552\\n00:00:2083\\nVery unpredictable.\\n553\\n00:00:2084\\nBut the bare minimum, but there is a bare minimum, which we can articulate.\\n554\\n00:00:2089\\nThat if such super, if such very, very intelligent, super intelligent data centers\\n555\\n00:00:2096\\nhave been built, been built at all,\\n556\\n00:00:2098\"), Document(page_content=\"329\\n00:00:1255\\nThat's self-evident.\\n330\\n00:00:1257\\nI do think though that as models continue to get larger and better, then they will unlock\\n331\\n00:00:1262\\nnew and unprecedentedly valuable applications.\\n332\\n00:00:1265\\nSo yeah, the small models will have their niche for the less interesting applications,\\n333\\n00:00:1269\\nwhich are still very useful.\\n334\\n00:00:1271\\nAnd then the bigger models will be delivering on applications.\\n335\\n00:00:1275\\nOkay, let's pick an example.\\n336\\n00:00:1278\\nConsider the task of producing good legal advice.\\n337\\n00:00:1282\\nIt's really valuable if you can really trust the answer.\\n338\\n00:00:1284\\nMaybe you need a much bigger model for it, but it justifies the cost.\\n339\\n00:00:1287\\nThere's been a lot of investment this year at the 7B in particular, but 7B, 13B, 34B\\n340\\n00:00:1295\\nsizes.\\n341\\n00:00:1296\\nDo you think continued research at those scales is wasted?\\n342\\n00:00:1301\\nNo, of course not.\\n343\\n00:00:1303\"), Document(page_content=\"434\\n00:00:1672\\namazing things, but maybe something else, maybe some modification could have some computer\\n435\\n00:00:1678\\nefficiency benefits.\\n436\\n00:00:1680\\nSo you also better to think about it in terms of computer efficiency rather than in terms\\n437\\n00:00:1683\\nof can it get there at all?\\n438\\n00:00:1685\\nI think at this point, the answer is obviously yes.\\n439\\n00:00:1689\\nTo the question about, well, what about the human brain and with its brain regions?\\n440\\n00:00:1694\\nI actually think that the situation there is subtle and deceptive for the following\\n441\\n00:00:1701\\nreasons.\\n442\\n00:00:1701\\nSo what I believe you alluded to is the fact that the human brain has known regions.\\n443\\n00:00:1706\\nIt has like, it has a speech perception region, it has a speech production region, it\\n444\\n00:00:1710\\nhas an image region, it has a face region, it has like all these regions, and it looks\\n445\\n00:00:1714\\nlike it's specialized.\\n446\\n00:00:1716\")]\n",
      "text='\\n                        As a content curator, summarize the content in the following transcript with in chapter with sentences that each chapter begin in using this The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"summarization\": {\"title\": \"Summarization\", \"description\": \"A short summarization of the transcript\", \"type\": \"string\"}, \"number_of_chapters\": {\"title\": \"Number Of Chapters\", \"description\": \"Number of chapters of main contents in this transcript\", \"type\": \"integer\"}, \"chapter\": {\"title\": \"Chapter\", \"description\": \"List of default=PydanticUndefined description=\\'Number of chapters of main contents in this transcript\\' extra={} short chapter name of main contents and the sentence that each chapter start with in the transcript, using this format \\'Chapter name:Sentence\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"sentences\": {\"title\": \"Sentences\", \"description\": \"List of default=PydanticUndefined description=\\'Number of chapters of main contents in this transcript\\' extra={} main contents in the transcript and the first sentence each default=PydanticUndefined description=\\\\\"List of default=PydanticUndefined description=\\'Number of chapters of main contents in this transcript\\' extra={} short chapter name of main contents and the sentence that each chapter start with in the transcript, using this format \\'Chapter name:Sentence\\\\\" extra={} begin with\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"summarization\", \"number_of_chapters\", \"chapter\", \"sentences\"]}\\n```\\n                        424\\n00:00:1629\\nareas of higher thought, areas for empathy or other sort of aspects of everything from personality\\n425\\n00:00:1634\\nto processing.\\n426\\n00:00:1636\\nDo you think that the transformer architectures are the main thing that will just keep going\\n427\\n00:00:1640\\nand get us there?\\n428\\n00:00:1641\\nDo you think we\\'ll need other architectures over time?\\n429\\n00:00:1643\\nSo I have to, I understand precisely what you\\'re saying and I have to answer to this question.\\n430\\n00:00:1650\\nThe first is that in my opinion, the best way to think about the question of architecture\\n431\\n00:00:1655\\nis not in terms of a binary, is it enough?\\n432\\n00:00:1659\\nBut how much effort, what will be the cost of using this particular architecture?\\n433\\n00:00:1667\\nLike at this point, I don\\'t think anyone doubts that the transformer architecture can do\\n434\\n00:00:1672\\namazing things, but maybe something else, maybe some modification could have some computer\\n435\\n00:00:1678\\nefficiency benefits.\\n436\\n00:00:1680\\n---\\n00:00:1182\\nOr like let\\'s suppose I upload some documents, some financial documents.\\n308\\n00:00:1186\\nSuppose they say something I want you to do some analysis and to make some conclusion\\n309\\n00:00:1189\\nand I want to take action on this basis and this conclusion.\\n310\\n00:00:1193\\nAnd it\\'s like it\\'s not a super hard task.\\n311\\n00:00:1195\\nAnd the model, these models clearly succeed on this task most of the time.\\n312\\n00:00:1199\\nBut because they don\\'t succeed all the time and if it\\'s a consequential decision I\\n313\\n00:00:1202\\nactually can\\'t trust the model any of those times.\\n314\\n00:00:1204\\nAnd I have to verify the answer somehow.\\n315\\n00:00:1207\\nSo that\\'s how I define reliability.\\n316\\n00:00:1208\\nIt\\'s very similar to the self-driving situation, right?\\n317\\n00:00:1210\\nIf you have a self-driving car and it\\'s like, does things mostly well?\\n318\\n00:00:1216\\nIt\\'s not good enough.\\n319\\n00:00:1217\\nSituation is not as extreme as with a self-driving car, but that\\'s what I mean by reliability.\\n320\\n00:00:1221\\n---\\n352\\n00:00:1341\\nwill justify the cost of a large model.\\n353\\n00:00:1343\\nWhat do you think the role of open sources in the ecosystem?\\n354\\n00:00:1347\\nWell, open source is complicated.\\n355\\n00:00:1349\\nI\\'ll describe to you my mental picture.\\n356\\n00:00:1352\\nI think that in the near term, open source is just helping companies produce useful.\\n357\\n00:00:1359\\nLike, let\\'s see.\\n358\\n00:00:1360\\nWhy would one want to have an open source, but using open source model instead of a\\n359\\n00:00:1365\\nclosed source model that\\'s hosted by some other company?\\n360\\n00:00:1368\\nI mean, I think it\\'s very valid to want to be the final decider on the exact way in\\n361\\n00:00:1377\\nwhich you want your model to be used.\\n362\\n00:00:1379\\nFor you to make the decision of exactly how you want the model to be used and which use\\n363\\n00:00:1384\\ncase you wish to support.\\n364\\n00:00:1386\\nAnd I think there\\'s going to be a lot of demand for open source models.\\n365\\n00:00:1388\\n---\\n540\\n00:00:2048\\nbut it also have mean have deeper insight into the same subjects that we people are studying\\n541\\n00:00:2055\\nand looking into.\\n542\\n00:00:2056\\nIt means learn even faster than people.\\n543\\n00:00:2061\\nLike, what could such a eyes do?\\n544\\n00:00:2063\\nI don\\'t know.\\n545\\n00:00:2064\\nCertainly, if such an AI were the basis of some artificial life, it would be,\\n546\\n00:00:2069\\nwell, how do you even think about it?\\n547\\n00:00:2071\\nIf you have some very powerful data center that\\'s also alive in a sense,\\n548\\n00:00:2076\\nthat\\'s what we\\'re talking about.\\n549\\n00:00:2078\\nAnd when I imagine this world, my reaction is, gosh,\\n550\\n00:00:2081\\nthis is very unpredictable.\\n551\\n00:00:2082\\nWhat\\'s going to happen?\\n552\\n00:00:2083\\nVery unpredictable.\\n553\\n00:00:2084\\nBut the bare minimum, but there is a bare minimum, which we can articulate.\\n554\\n00:00:2089\\nThat if such super, if such very, very intelligent, super intelligent data centers\\n555\\n00:00:2096\\nhave been built, been built at all,\\n556\\n00:00:2098\\n---\\n329\\n00:00:1255\\nThat\\'s self-evident.\\n330\\n00:00:1257\\nI do think though that as models continue to get larger and better, then they will unlock\\n331\\n00:00:1262\\nnew and unprecedentedly valuable applications.\\n332\\n00:00:1265\\nSo yeah, the small models will have their niche for the less interesting applications,\\n333\\n00:00:1269\\nwhich are still very useful.\\n334\\n00:00:1271\\nAnd then the bigger models will be delivering on applications.\\n335\\n00:00:1275\\nOkay, let\\'s pick an example.\\n336\\n00:00:1278\\nConsider the task of producing good legal advice.\\n337\\n00:00:1282\\nIt\\'s really valuable if you can really trust the answer.\\n338\\n00:00:1284\\nMaybe you need a much bigger model for it, but it justifies the cost.\\n339\\n00:00:1287\\nThere\\'s been a lot of investment this year at the 7B in particular, but 7B, 13B, 34B\\n340\\n00:00:1295\\nsizes.\\n341\\n00:00:1296\\nDo you think continued research at those scales is wasted?\\n342\\n00:00:1301\\nNo, of course not.\\n343\\n00:00:1303\\n---\\n434\\n00:00:1672\\namazing things, but maybe something else, maybe some modification could have some computer\\n435\\n00:00:1678\\nefficiency benefits.\\n436\\n00:00:1680\\nSo you also better to think about it in terms of computer efficiency rather than in terms\\n437\\n00:00:1683\\nof can it get there at all?\\n438\\n00:00:1685\\nI think at this point, the answer is obviously yes.\\n439\\n00:00:1689\\nTo the question about, well, what about the human brain and with its brain regions?\\n440\\n00:00:1694\\nI actually think that the situation there is subtle and deceptive for the following\\n441\\n00:00:1701\\nreasons.\\n442\\n00:00:1701\\nSo what I believe you alluded to is the fact that the human brain has known regions.\\n443\\n00:00:1706\\nIt has like, it has a speech perception region, it has a speech production region, it\\n444\\n00:00:1710\\nhas an image region, it has a face region, it has like all these regions, and it looks\\n445\\n00:00:1714\\nlike it\\'s specialized.\\n446\\n00:00:1716\\n                        '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(docs)\n",
    "\n",
    "\n",
    "message = prompt.format_prompt(transcript= \"\\n---\\n\".join([d.page_content for d in docs]))\n",
    "\n",
    "print(message)\n",
    "result = llm_chain(message.to_string())\n",
    "result\n",
    "parsed = output_parser.parse(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The transcript discusses various topics related to transformer architectures, reliability of models, the role of open source in the ecosystem, and the potential of super intelligent data centers. It also mentions the value of larger models for unlocking new applications and the importance of considering computer efficiency. The discussion highlights the complexity of the human brain's specialized regions.\n",
      "        5\n",
      "        ['Chapter 1: areas of higher thought, areas for empathy or other sort of aspects of everything from personality to processing.', 'Chapter 2: The definition of reliability and its similarity to the self-driving situation.', 'Chapter 3: The role of open source in the ecosystem and the demand for open source models.', 'Chapter 4: The potential of super intelligent data centers and the unpredictability of their impact.', 'Chapter 5: The value of larger models for unlocking new and valuable applications and the consideration of computer efficiency.']\n",
      "        ['Chapter 1: areas of higher thought, areas for empathy or other sort of aspects of everything from personality to processing.', 'Chapter 2: The definition of reliability and its similarity to the self-driving situation.', 'Chapter 3: The role of open source in the ecosystem and the demand for open source models.', 'Chapter 4: The potential of super intelligent data centers and the unpredictability of their impact.', 'Chapter 5: The value of larger models for unlocking new and valuable applications and the consideration of computer efficiency.']\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "        {parsed.summarization}\n",
    "        {parsed.number_of_chapters}\n",
    "        {parsed.chapter}\n",
    "        {parsed.sentences}\n",
    "    ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_gpt",
   "language": "python",
   "name": "local_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
